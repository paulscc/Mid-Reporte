{
  "hash": "94d184290699494db2dc197a5d5e4601",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Midterm 2\"\njupyter: python3\nauthor: \"Paul C \"\ndate: \"10-04-2025\"\nformat: \n    html:\n        embed-resources: true\n---\n\n::: {#5c42f4fa .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay, classification_report\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n```\n:::\n\n\n## Carga de dataset\n\n::: {#d7c99caf .cell execution_count=2}\n``` {.python .cell-code}\n# 1. CARGAR DATASET\nprint(\"=\"*70)\nprint(\"CLASIFICACIÓN DE CANCHAS - REGRESIÓN LOGÍSTICA\")\nprint(\"=\"*70)\n\ntry:\n    df = pd.read_csv('canchas.csv', sep=';', encoding='utf-8-sig')\nexcept:\n    df = pd.read_csv('canchas.csv', sep=';', encoding='latin-1')\n\ndf.columns = df.columns.str.strip().str.replace('ï»¿', '')\ndf = df.loc[:, df.columns != '']\ndf = df.loc[:, ~df.columns.str.match('^Unnamed')]\n\nprint(f\"Total de registros: {len(df)}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n======================================================================\nCLASIFICACIÓN DE CANCHAS - REGRESIÓN LOGÍSTICA\n======================================================================\nTotal de registros: 147\n```\n:::\n:::\n\n\n## Variable objetivo\n\n::: {#8ab64ea4 .cell execution_count=3}\n``` {.python .cell-code}\n# 2. VARIABLE OBJETIVO\ncosto_col = 'Costo por uso de las instalaciones'\ndf[costo_col] = pd.to_numeric(df[costo_col], errors='coerce')\ndf['tiene_costo'] = (df[costo_col] > 0).astype(int)\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"DISTRIBUCIÓN DE CLASES\")\nprint(\"=\"*70)\ndist = df['tiene_costo'].value_counts().sort_index()\ntotal = dist.sum()\nprint(f\"Gratis (0):    {dist.get(0, 0):3d} canchas ({dist.get(0, 0)/total*100:5.2f}%)\")\nprint(f\"Con costo (1): {dist.get(1, 0):3d} canchas ({dist.get(1, 0)/total*100:5.2f}%)\")\nprint(f\"\\nDesbalanceo de clases: {dist.get(0, 0)/dist.get(1, 0):.2f}:1\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n======================================================================\nDISTRIBUCIÓN DE CLASES\n======================================================================\nGratis (0):    133 canchas (90.48%)\nCon costo (1):  14 canchas ( 9.52%)\n\nDesbalanceo de clases: 9.50:1\n```\n:::\n:::\n\n\n## Seleccion de features\n\n::: {#43b9e374 .cell execution_count=4}\n``` {.python .cell-code}\n# 3. SELECCIONAR FEATURES\nfeatures_map = {\n    'zonal': None, 'provincia': None, 'canton': None, 'estado': None,\n    'cubierta': None, 'propiedad': None, 'uso': None\n}\n\nfor col in df.columns:\n    col_norm = col.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u')\n    if 'zonal' in col_norm or 'coordinacion' in col_norm:\n        features_map['zonal'] = col\n    elif 'provincia' in col_norm:\n        features_map['provincia'] = col\n    elif 'canton' in col_norm:\n        features_map['canton'] = col\n    elif 'estado' in col_norm:\n        features_map['estado'] = col\n    elif 'cubierta' in col_norm or 'caracteristica' in col_norm:\n        features_map['cubierta'] = col\n    elif 'propiedad' in col_norm and 'tipo' in col_norm:\n        features_map['propiedad'] = col\n    elif 'uso' in col_norm and 'escenario' in col_norm:\n        features_map['uso'] = col\n\nfeatures = [v for v in features_map.values() if v is not None]\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"FEATURES SELECCIONADAS\")\nprint(\"=\"*70)\nfor i, feat in enumerate(features, 1):\n    n_unique = df[feat].nunique()\n    print(f\"{i}. {feat}: {n_unique} categorías\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n======================================================================\nFEATURES SELECCIONADAS\n======================================================================\n1. Coordinación Zonal: 3 categorías\n2. Provincia: 7 categorías\n3. Cantón: 48 categorías\n4. Estado: 4 categorías\n5. Características de cubierta del escenario: 2 categorías\n6. Tipo de propiedad: 2 categorías\n7. Uso del escenario deportivo: 61 categorías\n```\n:::\n:::\n\n\n## Preparar datos\n\n::: {#49bb4b04 .cell execution_count=5}\n``` {.python .cell-code}\ndatos_validos = df[df['tiene_costo'].notna()]\ndf_model = datos_validos[features + ['tiene_costo']].copy()\n\nfor col in features:\n    df_model[col] = df_model[col].fillna('Desconocido')\n\ndf_model = df_model.drop_duplicates()\nprint(f\"\\nDatos finales: {len(df_model)} registros ({len(df_model)/len(df)*100:.1f}% del total)\")\n\n\n\n# 5. CODIFICAR\nencoders = {}\nfor col in features:\n    le = LabelEncoder()\n    df_model[col] = le.fit_transform(df_model[col].astype(str))\n    encoders[col] = le\n\nX = df_model[features].values\ny = df_model['tiene_costo'].values\n\n# 6. SPLIT\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"DIVISIÓN DE DATOS\")\nprint(\"=\"*70)\nprint(f\"Train: {len(X_train)} muestras (Gratis: {(y_train==0).sum()}, Con costo: {(y_train==1).sum()})\")\nprint(f\"Test:  {len(X_test)} muestras (Gratis: {(y_test==0).sum()}, Con costo: {(y_test==1).sum()})\")\n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nDatos finales: 122 registros (83.0% del total)\n\n======================================================================\nDIVISIÓN DE DATOS\n======================================================================\nTrain: 97 muestras (Gratis: 86, Con costo: 11)\nTest:  25 muestras (Gratis: 22, Con costo: 3)\n```\n:::\n:::\n\n\n## Pipeline\n\n::: {#77901a69 .cell execution_count=6}\n``` {.python .cell-code}\n# 7. PIPELINE CON REGRESIÓN LOGÍSTICA\nprint(\"\\n\" + \"=\"*70)\nprint(\"ENTRENANDO MODELO\")\nprint(\"=\"*70)\n\npipe = Pipeline([\n    ('escalado', StandardScaler()),\n    ('logreg', LogisticRegression(\n        max_iter=100000,\n        random_state=42,\n        class_weight='balanced'  # Maneja el desbalanceo de clases\n    ))\n])\n\nprint(\"Entrenando Regresión Logística con class_weight='balanced'...\")\npipe.fit(X_train, y_train)\nprint(\"✓ Modelo entrenado exitosamente\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n======================================================================\nENTRENANDO MODELO\n======================================================================\nEntrenando Regresión Logística con class_weight='balanced'...\n✓ Modelo entrenado exitosamente\n\n```\n:::\n:::\n\n\n## Predicciones\n\n::: {#54aba1d5 .cell execution_count=7}\n``` {.python .cell-code}\n# 8. PREDICCIONES\ny_pred_train = pipe.predict(X_train)\ny_pred_test = pipe.predict(X_test)\n\n```\n:::\n\n\n## Evaluacion\n\n::: {#8cb9e9ea .cell execution_count=8}\n``` {.python .cell-code}\nprint(\"=\"*70)\nprint(\"RESULTADOS - CONJUNTO DE ENTRENAMIENTO\")\nprint(\"=\"*70)\nacc_train = accuracy_score(y_train, y_pred_train)\nprec_train = precision_score(y_train, y_pred_train, zero_division=0)\nrec_train = recall_score(y_train, y_pred_train, zero_division=0)\nf1_train = f1_score(y_train, y_pred_train, zero_division=0)\n\nprint(f\"Accuracy:  {acc_train:.4f} ({acc_train*100:.2f}%)\")\nprint(f\"Precision: {prec_train:.4f} ({prec_train*100:.2f}%)\")\nprint(f\"Recall:    {rec_train:.4f} ({rec_train*100:.2f}%)\")\nprint(f\"F1-Score:  {f1_train:.4f} ({f1_train*100:.2f}%)\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n======================================================================\nRESULTADOS - CONJUNTO DE ENTRENAMIENTO\n======================================================================\nAccuracy:  0.6392 (63.92%)\nPrecision: 0.2000 (20.00%)\nRecall:    0.7273 (72.73%)\nF1-Score:  0.3137 (31.37%)\n```\n:::\n:::\n\n\n## Evaluacion\n\n::: {#6ab38062 .cell execution_count=9}\n``` {.python .cell-code}\n# 10. EVALUACIÓN - TEST\nprint(\"\\n\" + \"=\"*70)\nprint(\"RESULTADOS - CONJUNTO DE PRUEBA\")\nprint(\"=\"*70)\nacc_test = accuracy_score(y_test, y_pred_test)\nprec_test = precision_score(y_test, y_pred_test, zero_division=0)\nrec_test = recall_score(y_test, y_pred_test, zero_division=0)\nf1_test = f1_score(y_test, y_pred_test, zero_division=0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n======================================================================\nRESULTADOS - CONJUNTO DE PRUEBA\n======================================================================\n```\n:::\n:::\n\n\n## Evaluacion del modelo\n\n::: {#6bc9906e .cell execution_count=10}\n``` {.python .cell-code}\ndiferencia = abs(acc_train - acc_test)\n```\n:::\n\n\n## Visualizaciones\nVisualizaremos la matriz de confucion\n\n::: {#2d8f2818 .cell execution_count=11}\n``` {.python .cell-code}\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n\nConfusionMatrixDisplay.from_predictions(\n    y_test, y_pred_test,\n    display_labels=['Gratis', 'Con Costo'],\n    cmap='Blues',\n    ax=axes[0]\n)\naxes[0].set_title(f'Matriz de Confusión\\nAccuracy: {acc_test*100:.1f}%', \n                 fontsize=12, fontweight='bold')\n\n# Comparación de métricas Train vs Test\nmetricas = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\nvalores_train = [acc_train, prec_train, rec_train, f1_train]\nvalores_test = [acc_test, prec_test, rec_test, f1_test]\n\nx = np.arange(len(metricas))\nwidth = 0.35\n\naxes[1].bar(x - width/2, valores_train, width, label='Train', color='lightcoral', alpha=0.7)\naxes[1].bar(x + width/2, valores_test, width, label='Test', color='steelblue', alpha=0.7)\naxes[1].set_xlabel('Métricas', fontsize=11)\naxes[1].set_ylabel('Score', fontsize=11)\naxes[1].set_title('Comparación Train vs Test', fontweight='bold', fontsize=12)\naxes[1].set_xticks(x)\naxes[1].set_xticklabels(metricas, rotation=45, ha='right')\naxes[1].legend()\naxes[1].grid(axis='y', alpha=0.3)\naxes[1].set_ylim([0, 1.1])\n\n# Agregar valores en las barras\nfor i, v in enumerate(valores_train):\n    axes[1].text(i - width/2, v + 0.02, f'{v:.2f}', ha='center', va='bottom', fontsize=9)\nfor i, v in enumerate(valores_test):\n    axes[1].text(i + width/2, v + 0.02, f'{v:.2f}', ha='center', va='bottom', fontsize=9)\n\nplt.tight_layout()\nplt.show()\n\n```\n\n::: {.cell-output .cell-output-display}\n![](clasi_files/figure-html/cell-12-output-1.png){width=1199 height=470}\n:::\n:::\n\n\n### ROC, DISTRIBUCION DE CLASES Y  CURVA (GRAFICAS)\n    Se usara altair para es despliegue de estas graficas\n\n::: {#db108e34 .cell execution_count=12}\n``` {.python .cell-code}\nfrom sklearn.metrics import roc_curve, auc\n\ny_proba_test = pipe.predict_proba(X_test)[:, 1]\n\n\nfpr, tpr, thresholds = roc_curve(y_test, y_proba_test)\nroc_auc = auc(fpr, tpr)\n\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\nax1 = axes[0]\nclases = ['Gratis (0)', 'Con Costo (1)']\nvalores = [dist.get(0, 0), dist.get(1, 0)]\ncolores = ['#3498db', '#e74c3c']\n\nbars = ax1.bar(clases, valores, color=colores, alpha=0.7, edgecolor='black', linewidth=1.5)\nax1.set_ylabel('Cantidad de Canchas', fontsize=11, fontweight='bold')\nax1.set_title('Distribución de Clases en el Dataset', fontsize=12, fontweight='bold')\nax1.grid(axis='y', alpha=0.3, linestyle='--')\n\nfor bar, val in zip(bars, valores):\n    height = bar.get_height()\n    ax1.text(bar.get_x() + bar.get_width()/2., height,\n            f'{val}\\n({val/total*100:.1f}%)',\n            ha='center', va='bottom', fontsize=10, fontweight='bold')\n\nratio = dist.get(0, 0) / dist.get(1, 0)\nax1.text(0.5, max(valores)*0.9, f'Ratio de desbalanceo: {ratio:.1f}:1', \n         ha='center', fontsize=10, style='italic',\n         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n\nax2 = axes[1]\nax2.plot(fpr, tpr, color='#2ecc71', linewidth=2, label=f'ROC (AUC = {roc_auc:.3f})')\nax2.plot([0, 1], [0, 1], color='gray', linestyle='--', linewidth=1.5, label='Azar (AUC = 0.500)')\nax2.set_xlim([0.0, 1.0])\nax2.set_ylim([0.0, 1.05])\nax2.set_xlabel('Tasa de Falsos Positivos (FPR)', fontsize=11, fontweight='bold')\nax2.set_ylabel('Tasa de Verdaderos Positivos (TPR)', fontsize=11, fontweight='bold')\nax2.set_title('Curva ROC - Regresión Logística', fontsize=12, fontweight='bold')\nax2.legend(loc='lower right', fontsize=10)\nax2.grid(alpha=0.3, linestyle='--')\n\nax2.fill_between(fpr, tpr, alpha=0.2, color='#2ecc71')\n```\n\n::: {.cell-output .cell-output-display}\n![](clasi_files/figure-html/cell-13-output-1.png){width=1125 height=451}\n:::\n:::\n\n\n### Se puede observar como la canchas publicas tienen al mayor cantidad a diferencia de canchas con costo; los resultados reflejan la realidad, una mejor cantidad de datos nos podrian ser util para mejorar el modelo. \n\n",
    "supporting": [
      "clasi_files"
    ],
    "filters": [],
    "includes": {}
  }
}