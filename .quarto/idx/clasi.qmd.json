{"title":"Midterm 2","markdown":{"yaml":{"title":"Midterm 2","jupyter":"python3","author":"Paul C ","date":"10-04-2025","format":{"html":{"embed-resources":true}}},"headingText":"Carga de dataset","containsRefs":false,"markdown":"\n\n\n```{python}\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay, classification_report\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n```\n\n\n\n```{python}\n\n# 1. CARGAR DATASET\nprint(\"=\"*70)\nprint(\"CLASIFICACIÓN DE CANCHAS - REGRESIÓN LOGÍSTICA\")\nprint(\"=\"*70)\n\ntry:\n    df = pd.read_csv('canchas.csv', sep=';', encoding='utf-8-sig')\nexcept:\n    df = pd.read_csv('canchas.csv', sep=';', encoding='latin-1')\n\ndf.columns = df.columns.str.strip().str.replace('ï»¿', '')\ndf = df.loc[:, df.columns != '']\ndf = df.loc[:, ~df.columns.str.match('^Unnamed')]\n\nprint(f\"Total de registros: {len(df)}\")\n```\n\n## Variable objetivo\n\n\n```{python}\n# 2. VARIABLE OBJETIVO\ncosto_col = 'Costo por uso de las instalaciones'\ndf[costo_col] = pd.to_numeric(df[costo_col], errors='coerce')\ndf['tiene_costo'] = (df[costo_col] > 0).astype(int)\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"DISTRIBUCIÓN DE CLASES\")\nprint(\"=\"*70)\ndist = df['tiene_costo'].value_counts().sort_index()\ntotal = dist.sum()\nprint(f\"Gratis (0):    {dist.get(0, 0):3d} canchas ({dist.get(0, 0)/total*100:5.2f}%)\")\nprint(f\"Con costo (1): {dist.get(1, 0):3d} canchas ({dist.get(1, 0)/total*100:5.2f}%)\")\nprint(f\"\\nDesbalanceo de clases: {dist.get(0, 0)/dist.get(1, 0):.2f}:1\")\n```\n\n## Seleccion de features\n\n\n```{python}\n# 3. SELECCIONAR FEATURES\nfeatures_map = {\n    'zonal': None, 'provincia': None, 'canton': None, 'estado': None,\n    'cubierta': None, 'propiedad': None, 'uso': None\n}\n\nfor col in df.columns:\n    col_norm = col.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u')\n    if 'zonal' in col_norm or 'coordinacion' in col_norm:\n        features_map['zonal'] = col\n    elif 'provincia' in col_norm:\n        features_map['provincia'] = col\n    elif 'canton' in col_norm:\n        features_map['canton'] = col\n    elif 'estado' in col_norm:\n        features_map['estado'] = col\n    elif 'cubierta' in col_norm or 'caracteristica' in col_norm:\n        features_map['cubierta'] = col\n    elif 'propiedad' in col_norm and 'tipo' in col_norm:\n        features_map['propiedad'] = col\n    elif 'uso' in col_norm and 'escenario' in col_norm:\n        features_map['uso'] = col\n\nfeatures = [v for v in features_map.values() if v is not None]\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"FEATURES SELECCIONADAS\")\nprint(\"=\"*70)\nfor i, feat in enumerate(features, 1):\n    n_unique = df[feat].nunique()\n    print(f\"{i}. {feat}: {n_unique} categorías\")\n```\n\n## Preparar datos\n\n\n```{python}\ndatos_validos = df[df['tiene_costo'].notna()]\ndf_model = datos_validos[features + ['tiene_costo']].copy()\n\nfor col in features:\n    df_model[col] = df_model[col].fillna('Desconocido')\n\ndf_model = df_model.drop_duplicates()\nprint(f\"\\nDatos finales: {len(df_model)} registros ({len(df_model)/len(df)*100:.1f}% del total)\")\n\n\n\n# 5. CODIFICAR\nencoders = {}\nfor col in features:\n    le = LabelEncoder()\n    df_model[col] = le.fit_transform(df_model[col].astype(str))\n    encoders[col] = le\n\nX = df_model[features].values\ny = df_model['tiene_costo'].values\n\n# 6. SPLIT\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"DIVISIÓN DE DATOS\")\nprint(\"=\"*70)\nprint(f\"Train: {len(X_train)} muestras (Gratis: {(y_train==0).sum()}, Con costo: {(y_train==1).sum()})\")\nprint(f\"Test:  {len(X_test)} muestras (Gratis: {(y_test==0).sum()}, Con costo: {(y_test==1).sum()})\")\n\n\n```\n\n## Pipeline\n\n\n```{python}\n\n# 7. PIPELINE CON REGRESIÓN LOGÍSTICA\nprint(\"\\n\" + \"=\"*70)\nprint(\"ENTRENANDO MODELO\")\nprint(\"=\"*70)\n\npipe = Pipeline([\n    ('escalado', StandardScaler()),\n    ('logreg', LogisticRegression(\n        max_iter=100000,\n        random_state=42,\n        class_weight='balanced'  # Maneja el desbalanceo de clases\n    ))\n])\n\nprint(\"Entrenando Regresión Logística con class_weight='balanced'...\")\npipe.fit(X_train, y_train)\nprint(\"✓ Modelo entrenado exitosamente\\n\")\n\n```\n\n## Predicciones\n\n\n```{python}\n\n# 8. PREDICCIONES\ny_pred_train = pipe.predict(X_train)\ny_pred_test = pipe.predict(X_test)\n\n\n```\n\n## Evaluacion\n\n\n```{python}\n\nprint(\"=\"*70)\nprint(\"RESULTADOS - CONJUNTO DE ENTRENAMIENTO\")\nprint(\"=\"*70)\nacc_train = accuracy_score(y_train, y_pred_train)\nprec_train = precision_score(y_train, y_pred_train, zero_division=0)\nrec_train = recall_score(y_train, y_pred_train, zero_division=0)\nf1_train = f1_score(y_train, y_pred_train, zero_division=0)\n\nprint(f\"Accuracy:  {acc_train:.4f} ({acc_train*100:.2f}%)\")\nprint(f\"Precision: {prec_train:.4f} ({prec_train*100:.2f}%)\")\nprint(f\"Recall:    {rec_train:.4f} ({rec_train*100:.2f}%)\")\nprint(f\"F1-Score:  {f1_train:.4f} ({f1_train*100:.2f}%)\")\n\n```\n\n## Evaluacion\n\n\n```{python}\n\n# 10. EVALUACIÓN - TEST\nprint(\"\\n\" + \"=\"*70)\nprint(\"RESULTADOS - CONJUNTO DE PRUEBA\")\nprint(\"=\"*70)\nacc_test = accuracy_score(y_test, y_pred_test)\nprec_test = precision_score(y_test, y_pred_test, zero_division=0)\nrec_test = recall_score(y_test, y_pred_test, zero_division=0)\nf1_test = f1_score(y_test, y_pred_test, zero_division=0)\n\n```\n\n## Evaluacion del modelo\n\n\n```{python}\n\ndiferencia = abs(acc_train - acc_test)\n\n```\n\n## Visualizaciones\n\n\n```{python}\n\n# 12. VISUALIZACIONES\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Matriz de confusión\nConfusionMatrixDisplay.from_predictions(\n    y_test, y_pred_test,\n    display_labels=['Gratis', 'Con Costo'],\n    cmap='Blues',\n    ax=axes[0]\n)\naxes[0].set_title(f'Matriz de Confusión\\nAccuracy: {acc_test*100:.1f}%', \n                 fontsize=12, fontweight='bold')\n\n# Comparación de métricas Train vs Test\nmetricas = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\nvalores_train = [acc_train, prec_train, rec_train, f1_train]\nvalores_test = [acc_test, prec_test, rec_test, f1_test]\n\nx = np.arange(len(metricas))\nwidth = 0.35\n\naxes[1].bar(x - width/2, valores_train, width, label='Train', color='lightcoral', alpha=0.7)\naxes[1].bar(x + width/2, valores_test, width, label='Test', color='steelblue', alpha=0.7)\naxes[1].set_xlabel('Métricas', fontsize=11)\naxes[1].set_ylabel('Score', fontsize=11)\naxes[1].set_title('Comparación Train vs Test', fontweight='bold', fontsize=12)\naxes[1].set_xticks(x)\naxes[1].set_xticklabels(metricas, rotation=45, ha='right')\naxes[1].legend()\naxes[1].grid(axis='y', alpha=0.3)\naxes[1].set_ylim([0, 1.1])\n\n# Agregar valores en las barras\nfor i, v in enumerate(valores_train):\n    axes[1].text(i - width/2, v + 0.02, f'{v:.2f}', ha='center', va='bottom', fontsize=9)\nfor i, v in enumerate(valores_test):\n    axes[1].text(i + width/2, v + 0.02, f'{v:.2f}', ha='center', va='bottom', fontsize=9)\n\nplt.tight_layout()\nplt.show()\n\n\n```\n\n\n\n```{python}\nfrom sklearn.metrics import roc_curve, auc\n\n\n# Obtener probabilidades para la curva ROC\ny_proba_test = pipe.predict_proba(X_test)[:, 1]\n\n# Calcular curva ROC\nfpr, tpr, thresholds = roc_curve(y_test, y_proba_test)\nroc_auc = auc(fpr, tpr)\n\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n# GRÁFICA 1: Distribución de clases\nax1 = axes[0]\nclases = ['Gratis (0)', 'Con Costo (1)']\nvalores = [dist.get(0, 0), dist.get(1, 0)]\ncolores = ['#3498db', '#e74c3c']\n\nbars = ax1.bar(clases, valores, color=colores, alpha=0.7, edgecolor='black', linewidth=1.5)\nax1.set_ylabel('Cantidad de Canchas', fontsize=11, fontweight='bold')\nax1.set_title('Distribución de Clases en el Dataset', fontsize=12, fontweight='bold')\nax1.grid(axis='y', alpha=0.3, linestyle='--')\n\n# Agregar valores en las barras\nfor bar, val in zip(bars, valores):\n    height = bar.get_height()\n    ax1.text(bar.get_x() + bar.get_width()/2., height,\n            f'{val}\\n({val/total*100:.1f}%)',\n            ha='center', va='bottom', fontsize=10, fontweight='bold')\n\n# Agregar línea de desbalanceo\nratio = dist.get(0, 0) / dist.get(1, 0)\nax1.text(0.5, max(valores)*0.9, f'Ratio de desbalanceo: {ratio:.1f}:1', \n         ha='center', fontsize=10, style='italic',\n         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n\n# GRÁFICA 2: Curva ROC\nax2 = axes[1]\nax2.plot(fpr, tpr, color='#2ecc71', linewidth=2, label=f'ROC (AUC = {roc_auc:.3f})')\nax2.plot([0, 1], [0, 1], color='gray', linestyle='--', linewidth=1.5, label='Azar (AUC = 0.500)')\nax2.set_xlim([0.0, 1.0])\nax2.set_ylim([0.0, 1.05])\nax2.set_xlabel('Tasa de Falsos Positivos (FPR)', fontsize=11, fontweight='bold')\nax2.set_ylabel('Tasa de Verdaderos Positivos (TPR)', fontsize=11, fontweight='bold')\nax2.set_title('Curva ROC - Regresión Logística', fontsize=12, fontweight='bold')\nax2.legend(loc='lower right', fontsize=10)\nax2.grid(alpha=0.3, linestyle='--')\n\n# Sombrear área bajo la curva\nax2.fill_between(fpr, tpr, alpha=0.2, color='#2ecc71')\n\n```\n\n### Se puede observar como la canchas publicas tienen al mayor cantidad a diferencia de canchas con costo; los resultados reflejan la realidad. ","srcMarkdownNoYaml":"\n\n\n```{python}\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay, classification_report\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n```\n\n## Carga de dataset\n\n\n```{python}\n\n# 1. CARGAR DATASET\nprint(\"=\"*70)\nprint(\"CLASIFICACIÓN DE CANCHAS - REGRESIÓN LOGÍSTICA\")\nprint(\"=\"*70)\n\ntry:\n    df = pd.read_csv('canchas.csv', sep=';', encoding='utf-8-sig')\nexcept:\n    df = pd.read_csv('canchas.csv', sep=';', encoding='latin-1')\n\ndf.columns = df.columns.str.strip().str.replace('ï»¿', '')\ndf = df.loc[:, df.columns != '']\ndf = df.loc[:, ~df.columns.str.match('^Unnamed')]\n\nprint(f\"Total de registros: {len(df)}\")\n```\n\n## Variable objetivo\n\n\n```{python}\n# 2. VARIABLE OBJETIVO\ncosto_col = 'Costo por uso de las instalaciones'\ndf[costo_col] = pd.to_numeric(df[costo_col], errors='coerce')\ndf['tiene_costo'] = (df[costo_col] > 0).astype(int)\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"DISTRIBUCIÓN DE CLASES\")\nprint(\"=\"*70)\ndist = df['tiene_costo'].value_counts().sort_index()\ntotal = dist.sum()\nprint(f\"Gratis (0):    {dist.get(0, 0):3d} canchas ({dist.get(0, 0)/total*100:5.2f}%)\")\nprint(f\"Con costo (1): {dist.get(1, 0):3d} canchas ({dist.get(1, 0)/total*100:5.2f}%)\")\nprint(f\"\\nDesbalanceo de clases: {dist.get(0, 0)/dist.get(1, 0):.2f}:1\")\n```\n\n## Seleccion de features\n\n\n```{python}\n# 3. SELECCIONAR FEATURES\nfeatures_map = {\n    'zonal': None, 'provincia': None, 'canton': None, 'estado': None,\n    'cubierta': None, 'propiedad': None, 'uso': None\n}\n\nfor col in df.columns:\n    col_norm = col.lower().replace('á', 'a').replace('é', 'e').replace('í', 'i').replace('ó', 'o').replace('ú', 'u')\n    if 'zonal' in col_norm or 'coordinacion' in col_norm:\n        features_map['zonal'] = col\n    elif 'provincia' in col_norm:\n        features_map['provincia'] = col\n    elif 'canton' in col_norm:\n        features_map['canton'] = col\n    elif 'estado' in col_norm:\n        features_map['estado'] = col\n    elif 'cubierta' in col_norm or 'caracteristica' in col_norm:\n        features_map['cubierta'] = col\n    elif 'propiedad' in col_norm and 'tipo' in col_norm:\n        features_map['propiedad'] = col\n    elif 'uso' in col_norm and 'escenario' in col_norm:\n        features_map['uso'] = col\n\nfeatures = [v for v in features_map.values() if v is not None]\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"FEATURES SELECCIONADAS\")\nprint(\"=\"*70)\nfor i, feat in enumerate(features, 1):\n    n_unique = df[feat].nunique()\n    print(f\"{i}. {feat}: {n_unique} categorías\")\n```\n\n## Preparar datos\n\n\n```{python}\ndatos_validos = df[df['tiene_costo'].notna()]\ndf_model = datos_validos[features + ['tiene_costo']].copy()\n\nfor col in features:\n    df_model[col] = df_model[col].fillna('Desconocido')\n\ndf_model = df_model.drop_duplicates()\nprint(f\"\\nDatos finales: {len(df_model)} registros ({len(df_model)/len(df)*100:.1f}% del total)\")\n\n\n\n# 5. CODIFICAR\nencoders = {}\nfor col in features:\n    le = LabelEncoder()\n    df_model[col] = le.fit_transform(df_model[col].astype(str))\n    encoders[col] = le\n\nX = df_model[features].values\ny = df_model['tiene_costo'].values\n\n# 6. SPLIT\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"DIVISIÓN DE DATOS\")\nprint(\"=\"*70)\nprint(f\"Train: {len(X_train)} muestras (Gratis: {(y_train==0).sum()}, Con costo: {(y_train==1).sum()})\")\nprint(f\"Test:  {len(X_test)} muestras (Gratis: {(y_test==0).sum()}, Con costo: {(y_test==1).sum()})\")\n\n\n```\n\n## Pipeline\n\n\n```{python}\n\n# 7. PIPELINE CON REGRESIÓN LOGÍSTICA\nprint(\"\\n\" + \"=\"*70)\nprint(\"ENTRENANDO MODELO\")\nprint(\"=\"*70)\n\npipe = Pipeline([\n    ('escalado', StandardScaler()),\n    ('logreg', LogisticRegression(\n        max_iter=100000,\n        random_state=42,\n        class_weight='balanced'  # Maneja el desbalanceo de clases\n    ))\n])\n\nprint(\"Entrenando Regresión Logística con class_weight='balanced'...\")\npipe.fit(X_train, y_train)\nprint(\"✓ Modelo entrenado exitosamente\\n\")\n\n```\n\n## Predicciones\n\n\n```{python}\n\n# 8. PREDICCIONES\ny_pred_train = pipe.predict(X_train)\ny_pred_test = pipe.predict(X_test)\n\n\n```\n\n## Evaluacion\n\n\n```{python}\n\nprint(\"=\"*70)\nprint(\"RESULTADOS - CONJUNTO DE ENTRENAMIENTO\")\nprint(\"=\"*70)\nacc_train = accuracy_score(y_train, y_pred_train)\nprec_train = precision_score(y_train, y_pred_train, zero_division=0)\nrec_train = recall_score(y_train, y_pred_train, zero_division=0)\nf1_train = f1_score(y_train, y_pred_train, zero_division=0)\n\nprint(f\"Accuracy:  {acc_train:.4f} ({acc_train*100:.2f}%)\")\nprint(f\"Precision: {prec_train:.4f} ({prec_train*100:.2f}%)\")\nprint(f\"Recall:    {rec_train:.4f} ({rec_train*100:.2f}%)\")\nprint(f\"F1-Score:  {f1_train:.4f} ({f1_train*100:.2f}%)\")\n\n```\n\n## Evaluacion\n\n\n```{python}\n\n# 10. EVALUACIÓN - TEST\nprint(\"\\n\" + \"=\"*70)\nprint(\"RESULTADOS - CONJUNTO DE PRUEBA\")\nprint(\"=\"*70)\nacc_test = accuracy_score(y_test, y_pred_test)\nprec_test = precision_score(y_test, y_pred_test, zero_division=0)\nrec_test = recall_score(y_test, y_pred_test, zero_division=0)\nf1_test = f1_score(y_test, y_pred_test, zero_division=0)\n\n```\n\n## Evaluacion del modelo\n\n\n```{python}\n\ndiferencia = abs(acc_train - acc_test)\n\n```\n\n## Visualizaciones\n\n\n```{python}\n\n# 12. VISUALIZACIONES\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Matriz de confusión\nConfusionMatrixDisplay.from_predictions(\n    y_test, y_pred_test,\n    display_labels=['Gratis', 'Con Costo'],\n    cmap='Blues',\n    ax=axes[0]\n)\naxes[0].set_title(f'Matriz de Confusión\\nAccuracy: {acc_test*100:.1f}%', \n                 fontsize=12, fontweight='bold')\n\n# Comparación de métricas Train vs Test\nmetricas = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\nvalores_train = [acc_train, prec_train, rec_train, f1_train]\nvalores_test = [acc_test, prec_test, rec_test, f1_test]\n\nx = np.arange(len(metricas))\nwidth = 0.35\n\naxes[1].bar(x - width/2, valores_train, width, label='Train', color='lightcoral', alpha=0.7)\naxes[1].bar(x + width/2, valores_test, width, label='Test', color='steelblue', alpha=0.7)\naxes[1].set_xlabel('Métricas', fontsize=11)\naxes[1].set_ylabel('Score', fontsize=11)\naxes[1].set_title('Comparación Train vs Test', fontweight='bold', fontsize=12)\naxes[1].set_xticks(x)\naxes[1].set_xticklabels(metricas, rotation=45, ha='right')\naxes[1].legend()\naxes[1].grid(axis='y', alpha=0.3)\naxes[1].set_ylim([0, 1.1])\n\n# Agregar valores en las barras\nfor i, v in enumerate(valores_train):\n    axes[1].text(i - width/2, v + 0.02, f'{v:.2f}', ha='center', va='bottom', fontsize=9)\nfor i, v in enumerate(valores_test):\n    axes[1].text(i + width/2, v + 0.02, f'{v:.2f}', ha='center', va='bottom', fontsize=9)\n\nplt.tight_layout()\nplt.show()\n\n\n```\n\n\n\n```{python}\nfrom sklearn.metrics import roc_curve, auc\n\n\n# Obtener probabilidades para la curva ROC\ny_proba_test = pipe.predict_proba(X_test)[:, 1]\n\n# Calcular curva ROC\nfpr, tpr, thresholds = roc_curve(y_test, y_proba_test)\nroc_auc = auc(fpr, tpr)\n\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n# GRÁFICA 1: Distribución de clases\nax1 = axes[0]\nclases = ['Gratis (0)', 'Con Costo (1)']\nvalores = [dist.get(0, 0), dist.get(1, 0)]\ncolores = ['#3498db', '#e74c3c']\n\nbars = ax1.bar(clases, valores, color=colores, alpha=0.7, edgecolor='black', linewidth=1.5)\nax1.set_ylabel('Cantidad de Canchas', fontsize=11, fontweight='bold')\nax1.set_title('Distribución de Clases en el Dataset', fontsize=12, fontweight='bold')\nax1.grid(axis='y', alpha=0.3, linestyle='--')\n\n# Agregar valores en las barras\nfor bar, val in zip(bars, valores):\n    height = bar.get_height()\n    ax1.text(bar.get_x() + bar.get_width()/2., height,\n            f'{val}\\n({val/total*100:.1f}%)',\n            ha='center', va='bottom', fontsize=10, fontweight='bold')\n\n# Agregar línea de desbalanceo\nratio = dist.get(0, 0) / dist.get(1, 0)\nax1.text(0.5, max(valores)*0.9, f'Ratio de desbalanceo: {ratio:.1f}:1', \n         ha='center', fontsize=10, style='italic',\n         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n\n# GRÁFICA 2: Curva ROC\nax2 = axes[1]\nax2.plot(fpr, tpr, color='#2ecc71', linewidth=2, label=f'ROC (AUC = {roc_auc:.3f})')\nax2.plot([0, 1], [0, 1], color='gray', linestyle='--', linewidth=1.5, label='Azar (AUC = 0.500)')\nax2.set_xlim([0.0, 1.0])\nax2.set_ylim([0.0, 1.05])\nax2.set_xlabel('Tasa de Falsos Positivos (FPR)', fontsize=11, fontweight='bold')\nax2.set_ylabel('Tasa de Verdaderos Positivos (TPR)', fontsize=11, fontweight='bold')\nax2.set_title('Curva ROC - Regresión Logística', fontsize=12, fontweight='bold')\nax2.legend(loc='lower right', fontsize=10)\nax2.grid(alpha=0.3, linestyle='--')\n\n# Sombrear área bajo la curva\nax2.fill_between(fpr, tpr, alpha=0.2, color='#2ecc71')\n\n```\n\n### Se puede observar como la canchas publicas tienen al mayor cantidad a diferencia de canchas con costo; los resultados reflejan la realidad. "},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"paged","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"center","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"embed-resources":true,"output-file":"clasi.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.24","jupyter":"python3","theme":"cosmo","title":"Midterm 2","author":"Paul C ","date":"10-04-2025"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}